{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n",
      "1.1.0\n",
      "1.1.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import monai\n",
    "print(monai.__version__)\n",
    "import pandas \n",
    "print(pandas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified from 240714_main_(2D_add_slice).ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import ipynbname\n",
    "if '__file__' in globals():\n",
    "    FILENAME = os.getcwd() + '/' + os.path.basename(__file__)\n",
    "else:\n",
    "    try:\n",
    "        from ipynbname import name\n",
    "        FILENAME = os.getcwd() + '/' + name() + '.ipynb'\n",
    "    except ModuleNotFoundError:\n",
    "        FILENAME = os.getcwd() + '/notebook_name.ipynb'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandomResizedCrop\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from monai.losses import TverskyLoss as TverskyLoss\n",
    "from monai.transforms import Compose, ToTensor, RandFlip\n",
    "from monai.metrics import DiceMetric as Dice_Function\n",
    "from monai.metrics import compute_iou as IoU_Function\n",
    "from monai.metrics import ConfusionMatrixMetric\n",
    "\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "model_dir = 'models'\n",
    "# module_names = [py.replace('.py','') for py in os.listdir(model_dir)] ; module_names = list(set(module_names)-{'.ipynb_checkpoints','__pycache__'});\n",
    "module_names = ['DeepLab_V3_Plus_Effi_U_Trans2']\n",
    "Dataset_dir = 'CarDD_release/splits'\n",
    " \n",
    "model_names = module_names\n",
    "\n",
    "for  module_name in module_names:\n",
    "    exec(f'from {model_dir}.{module_name} import *')\n",
    "# dataset_path-training\n",
    "#         ㄴ V01_01_002.jpg, V01_01_002_mask.jpg, ...\n",
    "# ㄴvalidation\n",
    "#  ㄴtest\n",
    "\n",
    "iterations = [1, 10]\n",
    "# train_size=0.6\n",
    "\n",
    "in_channels = 3\n",
    "number_of_classes=1\n",
    "epochs = 100 # 125\n",
    "EARLY_STOP = 25  #25\n",
    "batch_size = 8\n",
    "\n",
    "devices = [0]\n",
    "\n",
    "optimizer = 'AdamW'\n",
    "lr = 1e-4\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "optim_args = {'optimizer': optimizer, 'lr': lr, 'momentum': momentum, 'weight_decay': weight_decay}\n",
    "\n",
    "lr_scheduler = 'CosineAnnealingLR'\n",
    "T_max = epochs\n",
    "T_0 = epochs\n",
    "eta_min = 1e-6\n",
    "lr_scheduler_args = {'lr_scheduler': lr_scheduler, 'T_max': T_max, 'T_0': T_0, 'eta_min': eta_min}\n",
    "\n",
    "loss_function = 'DiceBCELoss'\n",
    "#loss_function = 'DiceBCELoss'\n",
    "# loss_function = 'Tversky Focal Loss'\n",
    "reduction = 'mean'\n",
    "gamma = 2.0\n",
    "weight = None\n",
    "loss_function_args = {'loss_function': loss_function, 'reduction': reduction, 'gamma': gamma, 'weight': weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_random_seed(seed, pytorch=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available()==True:\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "    except:\n",
    "        pass\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "def imread_kor ( filePath, mode=cv2.IMREAD_UNCHANGED ) : \n",
    "    stream = open( filePath.encode(\"utf-8\") , \"rb\") \n",
    "    bytes = bytearray(stream.read()) \n",
    "    numpyArray = np.asarray(bytes, dtype=np.uint8)\n",
    "    return cv2.imdecode(numpyArray , mode)\n",
    "def imwrite_kor(filename, img, params=None): \n",
    "    try: \n",
    "        ext = os.path.splitext(filename)[1] \n",
    "        result, n = cv2.imencode(ext, img, params) \n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f: \n",
    "                n.tofile(f) \n",
    "                return True\n",
    "        else: \n",
    "            return False \n",
    "    except Exception as e: \n",
    "        print(e) \n",
    "        return False\n",
    "    \n",
    "def random_rotation(image, mask, angle_range=(-30, 30)):\n",
    "    # 지정된 각도 범위 내에서 무작위로 각도 선택\n",
    "    angle = random.uniform(angle_range[0], angle_range[1])\n",
    "    # 이미지와 마스크를 동일한 각도로 회전\n",
    "    image = TF.rotate(image, angle)\n",
    "    mask = TF.rotate(mask, angle)\n",
    "    return image, mask\n",
    "\n",
    "def load_coco_data(base_dataset_dir, sub_dirs=['training', 'validation', 'test']):\n",
    "    data = {}\n",
    "    for sub_dir in sub_dirs:\n",
    "        # 각 폴더의 JSON 파일 경로\n",
    "        json_path = os.path.join(base_dataset_dir, sub_dir, f\"{sub_dir}_data.json\")\n",
    "        \n",
    "        # JSON 파일 로드\n",
    "        with open(json_path, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "        \n",
    "        # 이미지와 주석 매핑\n",
    "        images = {img[\"id\"]: img for img in coco_data[\"images\"]}\n",
    "        annotations = {}\n",
    "        for ann in coco_data[\"annotations\"]:\n",
    "            image_id = ann[\"image_id\"]\n",
    "            if image_id not in annotations:\n",
    "                annotations[image_id] = []\n",
    "            annotations[image_id].append(ann)\n",
    "        \n",
    "        data[sub_dir] = {\n",
    "            \"images\": images,\n",
    "            \"annotations\": annotations\n",
    "        }\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_mask(image_size, annotations):\n",
    "    \"\"\"\n",
    "    COCO annotation의 segmentation 정보를 활용해 마스크 생성\n",
    "    \"\"\"\n",
    "    mask = Image.new(\"L\", (image_size[1], image_size[0]), 0)  # L = grayscale\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    \n",
    "    for ann in annotations:\n",
    "        segmentation = ann[\"segmentation\"]\n",
    "        for polygon in segmentation:\n",
    "            draw.polygon(polygon, outline=1, fill=1)\n",
    "    \n",
    "    return np.array(mask)\n",
    "\n",
    "class ImagesDataset(Dataset):\n",
    "    def __init__(self, images, annotations, image_dir, aug=False):\n",
    "        self.images = list(images.values())  # 이미지 정보를 리스트로 변환\n",
    "        self.annotations = annotations\n",
    "        self.image_dir = image_dir\n",
    "        self.aug = aug\n",
    "        self.desired_height = 256\n",
    "        self.desired_width = 256\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_info = self.images[idx]\n",
    "        image_id = image_info[\"id\"]\n",
    "        image_path = os.path.join(self.image_dir, image_info[\"file_name\"])\n",
    "        \n",
    "        # 이미지 로드\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = image.resize((self.desired_width, self.desired_height), resample=Image.BILINEAR)\n",
    "        \n",
    "        # 마스크 생성\n",
    "        annotations = self.annotations.get(image_id, [])\n",
    "        mask = create_mask((image_info[\"height\"], image_info[\"width\"]), annotations)\n",
    "        mask = Image.fromarray(mask).resize((self.desired_width, self.desired_height), resample=Image.NEAREST)\n",
    "        \n",
    "        # 데이터 증강\n",
    "        if self.aug:\n",
    "            if random.random() < 0.5:\n",
    "                image = TF.hflip(image)\n",
    "                mask = TF.hflip(mask)\n",
    "            if random.random() < 0.5:\n",
    "                angle = random.uniform(-30, 30)\n",
    "                image = TF.rotate(image, angle, interpolation=InterpolationMode.BILINEAR)\n",
    "                mask = TF.rotate(mask, angle, interpolation=InterpolationMode.NEAREST)\n",
    "        \n",
    "        # 텐서로 변환\n",
    "        image = TF.to_tensor(image).float()\n",
    "        mask = torch.from_numpy(np.array(mask)).float()\n",
    "        mask[mask > 0] = 1.0\n",
    "        if mask.dim() == 2:\n",
    "            mask = mask.unsqueeze(0)\n",
    "        \n",
    "        return image, mask, image_path\n",
    "\n",
    "def create_dataloader(coco_data, sub_dir, image_dir, batch_size, aug=False):\n",
    "    dataset = ImagesDataset(\n",
    "        images=coco_data[sub_dir][\"images\"],\n",
    "        annotations=coco_data[sub_dir][\"annotations\"],\n",
    "        image_dir=image_dir,\n",
    "        aug=aug\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=(sub_dir == \"training\"),\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def Pixel_Accuracy(yhat, ytrue, threshold=0.5):\n",
    "    yhat = yhat>threshold\n",
    "    if ytrue.dim() == 3:\n",
    "        ytrue = ytrue.unsqueeze(1)\n",
    "    correct = torch.sum(yhat == ytrue)\n",
    "    total = ytrue.numel()\n",
    "    accuracy = correct.float() / total\n",
    "    return accuracy.item()\n",
    "\n",
    "def Intersection_over_Union(yhat, ytrue, threshold=0.5):\n",
    "    yhat = yhat>threshold\n",
    "    if ytrue.dim() == 3:\n",
    "        ytrue = ytrue.unsqueeze(1)\n",
    "    return IoU_Function(yhat, ytrue).nanmean().item()\n",
    " \n",
    "def Dice_Coefficient(yhat, ytrue, threshold=0.5):\n",
    "    yhat = yhat>threshold\n",
    "    if ytrue.dim() == 3:\n",
    "        ytrue = ytrue.unsqueeze(1)\n",
    "    return Dice_Function()(yhat, ytrue).nanmean().item()\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # 시그모이드 함수 적용하여 예측 확률 계산\n",
    "        inputs_sigmoid = torch.sigmoid(inputs)\n",
    "        \n",
    "        intersection = (inputs_sigmoid * targets).sum()                           \n",
    "        dice_loss = 1 - (2. * intersection + smooth) / (inputs_sigmoid.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy_with_logits(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE\n",
    "\n",
    "class DiceCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, smooth=1.0):\n",
    "        \"\"\"\n",
    "        Dice + Cross-Entropy Loss\n",
    "        Args:\n",
    "            weight (list or None): 각 클래스의 가중치 (Cross-Entropy에서 사용)\n",
    "            smooth (float): Dice 손실 계산 시 안정성을 위한 smoothing 값\n",
    "        \"\"\"\n",
    "        super(DiceCELoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (torch.Tensor): 모델의 출력 (logits, shape: [batch, num_classes, height, width])\n",
    "            targets (torch.Tensor): 정답 레이블 (shape: [batch, height, width] 또는 [batch, num_classes, height, width])\n",
    "        Returns:\n",
    "            torch.Tensor: Dice + Cross-Entropy 손실 값\n",
    "        \"\"\"\n",
    "        # 예측 결과를 확률로 변환\n",
    "        inputs = torch.softmax(inputs, dim=1)\n",
    "        \n",
    "        # Dice Loss 계산\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=inputs.size(1)).permute(0, 3, 1, 2).float()\n",
    "        intersection = (inputs * targets_one_hot).sum(dim=(2, 3))\n",
    "        dice_loss = 1 - (2. * intersection + self.smooth) / (inputs.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3)) + self.smooth)\n",
    "        dice_loss = dice_loss.mean()  # 배치 평균\n",
    "\n",
    "        # Cross-Entropy Loss 계산\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.weight, reduction='mean')\n",
    "\n",
    "        return dice_loss + ce_loss\n",
    "    \n",
    "def Confusion_Matrix(yhat, ytrue, threshold=0.5):\n",
    "    yhat = yhat>threshold\n",
    "    confusion_matrix = ConfusionMatrixMetric(metric_name = [\"recall\", \"precision\", \"f1 score\"], reduction ='mean', compute_sample =True)\n",
    "    confusion_matrix(yhat, ytrue)\n",
    "    recall, precision, f1 = confusion_matrix.aggregate()\n",
    "    return recall, precision, f1\n",
    "    \n",
    "def train(train_loader, epoch, \\\n",
    "          model, criterion, optimizer, device\n",
    "          ):\n",
    "    model.train()\n",
    "    train_losses=AverageMeter()\n",
    "    for i, (input, target, _) in enumerate(train_loader):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(input)\n",
    "\n",
    "        # target이 output과 동일한 크기를 갖도록 함\n",
    "        if target.dim() == 3:\n",
    "            target = target.unsqueeze(1)\n",
    "\n",
    "        loss = criterion(output,target).float()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.update(loss.detach().cpu().numpy(),input.shape[0])\n",
    "    Train_Loss=np.round(train_losses.avg,6)\n",
    "    return Train_Loss\n",
    "def validate(validation_loader, \n",
    "          model, criterion, device,\n",
    "        model_path=False,\n",
    "             return_image_paths=False,\n",
    "          ):\n",
    "    if model_path!=False:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    for i, (input, target, image_path) in enumerate(validation_loader):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "        if i==0:\n",
    "            targets=target\n",
    "            outputs=output\n",
    "            if return_image_paths==True:\n",
    "                image_paths = image_path\n",
    "        else:\n",
    "            targets=torch.cat((targets,target))\n",
    "            outputs=torch.cat((outputs,output),axis=0)\n",
    "            if return_image_paths==True:\n",
    "                image_paths += image_path\n",
    "    if return_image_paths==True:\n",
    "        return outputs, targets, image_paths\n",
    "    return outputs, targets\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)\n",
    "\n",
    "def copy_sourcefile(output_dir, src_dir = 'src' ):    \n",
    "    import os \n",
    "    import shutil\n",
    "    import glob \n",
    "    source_dir = os.path.join(output_dir, src_dir)\n",
    "\n",
    "    os.makedirs(source_dir, exist_ok=True)\n",
    "    org_files1 = os.path.join('./', '*.py' )\n",
    "    org_files2 = os.path.join('./', '*.sh' )\n",
    "    org_files3 = os.path.join('./', '*.ipynb' )\n",
    "    org_files4 = os.path.join('./', '*.txt' )\n",
    "    org_files5 = os.path.join('./', '*.json' )    \n",
    "    files =[]\n",
    "    files = glob.glob(org_files1 )\n",
    "    files += glob.glob(org_files2  )\n",
    "    files += glob.glob(org_files3  )\n",
    "    files += glob.glob(org_files4  ) \n",
    "    files += glob.glob(org_files5  )     \n",
    "\n",
    "    # print(\"COPY source to output/source dir \", files)\n",
    "    tgt_files = os.path.join( source_dir, '.' )\n",
    "    for i, file in enumerate(files):\n",
    "        shutil.copy(file, tgt_files)\n",
    "class LossSaver(object):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    def reset(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    def update(self, train_loss, val_loss):\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.val_losses.append(val_loss)\n",
    "    def return_list(self):\n",
    "        return self.train_losses, self.val_losses\n",
    "    def save_as_csv(self, csv_file):\n",
    "        df = pd.DataFrame({'Train Losses': self.train_losses, 'Validation Losses': self.val_losses})\n",
    "        df.index = [f\"{i+1} Epoch\" for i in df.index]\n",
    "        df.to_csv(csv_file, index=True)\n",
    "class AverageMeter (object):\n",
    "    def __init__(self):\n",
    "        self.reset ()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "                \n",
    "def collect_image_paths(base_dataset_dir, sub_dirs=['training', 'validation', 'test']):\n",
    "    train_image_path_list = []\n",
    "    train_target_path_list = []\n",
    "    validation_image_path_list = []\n",
    "    validation_target_path_list = []\n",
    "    test_image_path_list = []\n",
    "    test_target_path_list = []\n",
    "    \n",
    "    # 서브 디렉토리 이름과 리스트 매핑\n",
    "    dir_to_lists = {\n",
    "        'training': (train_image_path_list, train_target_path_list),\n",
    "        'validation': (validation_image_path_list, validation_target_path_list),\n",
    "        'test': (test_image_path_list, test_target_path_list)\n",
    "    }\n",
    "    \n",
    "    for sub_dir in sub_dirs:\n",
    "        # 각 서브 디렉토리의 전체 경로를 생성\n",
    "        full_dir_path = os.path.join(base_dataset_dir, sub_dir)\n",
    "        \n",
    "        # 해당 서브 디렉토리에 대한 이미지 및 마스크 리스트 선택\n",
    "        image_list, target_list = dir_to_lists.get(sub_dir, (None, None))\n",
    "        \n",
    "        if image_list is None or target_list is None:\n",
    "            print(f\"Unknown sub-directory: {sub_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # 서브 디렉토리 내의 파일들을 검색\n",
    "        for file_name in os.listdir(full_dir_path):\n",
    "            # 이미지 파일이 .jpg 확장자이며 마스크 파일이 아닌지 확인\n",
    "            if file_name.endswith(\".jpg\") and \"_mask\" not in file_name:\n",
    "                # 이미지 파일의 전체 경로를 image_list에 추가\n",
    "                image_list.append(os.path.join(full_dir_path, file_name))\n",
    "                \n",
    "                # 마스크 파일 이름 생성 (.jpg를 _mask.png로 변경)\n",
    "                mask_file_name = file_name.replace(\".jpg\", \"_mask.png\")\n",
    "                \n",
    "                # 마스크 파일의 전체 경로를 target_list에 추가\n",
    "                target_list.append(os.path.join(full_dir_path, mask_file_name))\n",
    "    \n",
    "    return (train_image_path_list, train_target_path_list,\n",
    "            validation_image_path_list, validation_target_path_list,\n",
    "            test_image_path_list, test_target_path_list)\n",
    "\n",
    "def Do_Experiment(iteration, model_name, model, train_loader, validation_loader, test_loader, Optimizer, lr,  number_of_classes, epochs, Metrics,df,device, transform):\n",
    "    start = timeit.default_timer()\n",
    "    train_bool=True\n",
    "    test_bool=True\n",
    "    if loss_function == 'Tversky Focal Loss':\n",
    "        criterion=TverskyLoss()\n",
    "    elif loss_function == 'DiceBCELoss': ##원래 DiceBCELoss\n",
    "        criterion=DiceBCELoss()\n",
    "    if Optimizer=='Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif Optimizer == 'SGD':\n",
    "        momentum = 0.9\n",
    "        weight_decay = 1e-4\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum ,weight_decay=weight_decay)\n",
    "    elif Optimizer =='AdamW':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    if lr_scheduler_args['lr_scheduler'] == 'CosineAnnealingLR':\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = lr_scheduler_args['T_max'], eta_min = lr_scheduler_args['eta_min'])\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    control_random_seed(seed)\n",
    "    if train_bool:\n",
    "        now = datetime.now()\n",
    "        Train_date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "        print('Training Start Time:',Train_date)\n",
    "        best=9999\n",
    "        best_epoch=1\n",
    "        Early_Stop=0\n",
    "        loss_saver = LossSaver()\n",
    "        train_start_time = timeit.default_timer()\n",
    "        for epoch in range(1, epochs+1):\n",
    "            Train_Loss = train(train_loader, epoch, \n",
    "              model, criterion, optimizer, device\n",
    "              )\n",
    "            lr_scheduler.step()\n",
    "            outputs, targets  \\\n",
    "            = validate(validation_loader, \n",
    "              model, criterion, device\n",
    "              )\n",
    "            Val_Loss = np.round(criterion(outputs,targets).cpu().numpy(),6)            \n",
    "            iou = np.round(Intersection_over_Union(outputs, targets),3)\n",
    "            dice = np.round(Dice_Coefficient(outputs, targets),3)\n",
    "            now = datetime.now()\n",
    "            date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "            print(str(epoch)+'EP('+date+'):',end=' ')\n",
    "            print('T_Loss: ' + str(Train_Loss), end=' ')\n",
    "            print('V_Loss: ' + str(Val_Loss), end=' ')\n",
    "            print('IoU: ' + str(iou), end=' ')\n",
    "            print('Dice: ' + str(dice), end=' ')\n",
    "            \n",
    "            loss_saver.update(Train_Loss, Val_Loss)\n",
    "            loss_saver.save_as_csv(f'{output_dir}/Losses_{Experiments_Time}.csv')\n",
    "            if Val_Loss<best:\n",
    "                Early_Stop = 0\n",
    "                torch.save(model.state_dict(), f'{output_dir}/{Train_date}_{model_name}_Iter_{iteration}.pt')\n",
    "                best_epoch = epoch\n",
    "                best = Val_Loss\n",
    "                print('Best Epoch:',best_epoch,'Loss:',Val_Loss)\n",
    "            else:\n",
    "                print('')\n",
    "                Early_Stop+=1\n",
    "            if Early_Stop>=EARLY_STOP:\n",
    "                break\n",
    "        train_stop_time = timeit.default_timer()\n",
    "    if test_bool:\n",
    "        now = datetime.now()\n",
    "        date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "        print('Test Start Time:',date)\n",
    "        outputs, targets, image_paths \\\n",
    "            = validate(test_loader, \n",
    "              model, criterion, device,\n",
    "            model_path=f'{output_dir}/{Train_date}_{model_name}_Iter_{iteration}.pt',\n",
    "                       return_image_paths=True\n",
    "              )        \n",
    "        Loss = np.round(criterion(outputs,targets).cpu().numpy(),6)\n",
    "        pa = np.round(Pixel_Accuracy(outputs.cpu(), targets.cpu()),3)\n",
    "        iou = np.round(Intersection_over_Union(outputs, targets),3)\n",
    "        dice = np.round(Dice_Coefficient(outputs, targets),3)\n",
    "        recall, precision, f1 = Confusion_Matrix(outputs, targets) \n",
    "        recall = np.round(recall.cpu().numpy()[0],3); precision = np.round(precision.cpu().numpy()[0],3); f1 = np.round(f1.cpu().numpy()[0],3);\n",
    "                \n",
    "        now = datetime.now()\n",
    "        date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "        print('Best Epoch:',best_epoch)\n",
    "        print('Test('+date+'): '+'Loss: ' + str(Loss),end=' ')\n",
    "        print('PA: ' + str(pa), end=' ')\n",
    "        print('IoU: ' + str(iou), end=' ')\n",
    "        print('Dice: ' + str(dice), end=' ')\n",
    "        print('Recall: ' + str(recall), end=' ')\n",
    "        print('Precision: ' + str(precision), end=' ')\n",
    "        print('F1 Score: ' + str(f1), end='\\n')\n",
    "                            \n",
    "        stop = timeit.default_timer();m, s = divmod((train_stop_time - train_start_time)/epoch, 60);h, m = divmod(m, 60);Time_per_Epoch = \"%02d:%02d:%02d\" % (h, m, s);\n",
    "        m, s = divmod(stop - start, 60);h, m = divmod(m, 60);Time = \"%02d:%02d:%02d\" % (h, m, s);\n",
    "        total_params = sum(p.numel() for p in model.parameters()); total_params = format(total_params , ',');\n",
    "        Performances = [Experiments_Time, Train_date, iteration, model_name, best, Loss, pa, iou, dice, recall, precision, f1, total_params,Time, best_epoch, Time_per_Epoch, loss_function, lr, batch_size, epochs, FILENAME]\n",
    "        df = df.append(pd.Series(Performances, index=df.columns), ignore_index=True)\n",
    "        os.makedirs(f'{output_dir}/test_outputs', exist_ok = True)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        for output, image_path in zip(outputs, image_paths):\n",
    "            np.save(f'{output_dir}/test_outputs/{os.path.basename(image_path)}', output)\n",
    "    now = datetime.now()\n",
    "    date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "    print('End',date)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Start Time: 250411_222419\n",
      "DeepLab_V3_Plus_Effi_U_Trans2 (Iter 1)\n",
      "2025-04-11 22:24:23,347 - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b5.sw_in12k_ft_in1k)\n",
      "2025-04-11 22:24:23,885 - [timm/efficientnet_b5.sw_in12k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-04-11 22:24:28,642 - Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Training Start Time: 250411_222444\n",
      "1EP(250411_222607): T_Loss: 0.995703 V_Loss: 0.740364 IoU: 0.54 Dice: 0.648 Best Epoch: 1 Loss: 0.740364\n",
      "2EP(250411_222636): T_Loss: 0.772316 V_Loss: 0.639074 IoU: 0.529 Dice: 0.633 Best Epoch: 2 Loss: 0.639074\n",
      "3EP(250411_222707): T_Loss: 0.641473 V_Loss: 0.541569 IoU: 0.591 Dice: 0.69 Best Epoch: 3 Loss: 0.541569\n",
      "4EP(250411_222737): T_Loss: 0.540339 V_Loss: 0.459041 IoU: 0.607 Dice: 0.706 Best Epoch: 4 Loss: 0.459041\n",
      "5EP(250411_222808): T_Loss: 0.470142 V_Loss: 0.431871 IoU: 0.63 Dice: 0.728 Best Epoch: 5 Loss: 0.431871\n",
      "6EP(250411_222840): T_Loss: 0.409927 V_Loss: 0.405718 IoU: 0.637 Dice: 0.736 Best Epoch: 6 Loss: 0.405718\n",
      "7EP(250411_222913): T_Loss: 0.3765 V_Loss: 0.367123 IoU: 0.651 Dice: 0.745 Best Epoch: 7 Loss: 0.367123\n",
      "8EP(250411_222946): T_Loss: 0.334902 V_Loss: 0.356537 IoU: 0.654 Dice: 0.748 Best Epoch: 8 Loss: 0.356537\n",
      "9EP(250411_223021): T_Loss: 0.304455 V_Loss: 0.351787 IoU: 0.664 Dice: 0.758 Best Epoch: 9 Loss: 0.351787\n",
      "10EP(250411_223056): T_Loss: 0.276836 V_Loss: 0.341659 IoU: 0.664 Dice: 0.758 Best Epoch: 10 Loss: 0.341659\n",
      "11EP(250411_223132): T_Loss: 0.259519 V_Loss: 0.349294 IoU: 0.646 Dice: 0.743 \n",
      "12EP(250411_223207): T_Loss: 0.252713 V_Loss: 0.358789 IoU: 0.664 Dice: 0.759 \n",
      "13EP(250411_223242): T_Loss: 0.242415 V_Loss: 0.3446 IoU: 0.664 Dice: 0.758 \n",
      "14EP(250411_223318): T_Loss: 0.224331 V_Loss: 0.34431 IoU: 0.679 Dice: 0.773 \n",
      "15EP(250411_223353): T_Loss: 0.214874 V_Loss: 0.347928 IoU: 0.668 Dice: 0.762 \n",
      "16EP(250411_223429): T_Loss: 0.208372 V_Loss: 0.360784 IoU: 0.665 Dice: 0.761 \n",
      "17EP(250411_223505): T_Loss: 0.20178 V_Loss: 0.356368 IoU: 0.672 Dice: 0.768 \n",
      "18EP(250411_223541): T_Loss: 0.196473 V_Loss: 0.339208 IoU: 0.679 Dice: 0.772 Best Epoch: 18 Loss: 0.339208\n",
      "19EP(250411_223618): T_Loss: 0.186742 V_Loss: 0.357265 IoU: 0.678 Dice: 0.772 \n",
      "20EP(250411_223654): T_Loss: 0.172508 V_Loss: 0.337389 IoU: 0.693 Dice: 0.788 Best Epoch: 20 Loss: 0.337389\n",
      "21EP(250411_223731): T_Loss: 0.16586 V_Loss: 0.340165 IoU: 0.681 Dice: 0.774 \n",
      "22EP(250411_223808): T_Loss: 0.17379 V_Loss: 0.3538 IoU: 0.683 Dice: 0.778 \n",
      "23EP(250411_223844): T_Loss: 0.170465 V_Loss: 0.351356 IoU: 0.681 Dice: 0.773 \n",
      "24EP(250411_223921): T_Loss: 0.15837 V_Loss: 0.344658 IoU: 0.689 Dice: 0.781 \n",
      "25EP(250411_223958): T_Loss: 0.154116 V_Loss: 0.369217 IoU: 0.681 Dice: 0.774 \n",
      "26EP(250411_224035): T_Loss: 0.149026 V_Loss: 0.345387 IoU: 0.686 Dice: 0.78 \n",
      "27EP(250411_224112): T_Loss: 0.153075 V_Loss: 0.374143 IoU: 0.672 Dice: 0.769 \n",
      "28EP(250411_224149): T_Loss: 0.149081 V_Loss: 0.35441 IoU: 0.687 Dice: 0.78 \n",
      "29EP(250411_224226): T_Loss: 0.142936 V_Loss: 0.404939 IoU: 0.677 Dice: 0.772 \n",
      "30EP(250411_224304): T_Loss: 0.148495 V_Loss: 0.372473 IoU: 0.687 Dice: 0.781 \n",
      "31EP(250411_224342): T_Loss: 0.134292 V_Loss: 0.359829 IoU: 0.69 Dice: 0.782 \n",
      "32EP(250411_224419): T_Loss: 0.123434 V_Loss: 0.352701 IoU: 0.699 Dice: 0.791 \n",
      "33EP(250411_224457): T_Loss: 0.122273 V_Loss: 0.361964 IoU: 0.691 Dice: 0.787 \n",
      "34EP(250411_224535): T_Loss: 0.125839 V_Loss: 0.376201 IoU: 0.693 Dice: 0.788 \n",
      "35EP(250411_224612): T_Loss: 0.117331 V_Loss: 0.391087 IoU: 0.693 Dice: 0.786 \n",
      "36EP(250411_224650): T_Loss: 0.11915 V_Loss: 0.375667 IoU: 0.694 Dice: 0.787 \n",
      "37EP(250411_224727): T_Loss: 0.119817 V_Loss: 0.360086 IoU: 0.688 Dice: 0.781 \n",
      "38EP(250411_224805): T_Loss: 0.120973 V_Loss: 0.375972 IoU: 0.691 Dice: 0.784 \n",
      "39EP(250411_224843): T_Loss: 0.115836 V_Loss: 0.376558 IoU: 0.68 Dice: 0.775 \n",
      "40EP(250411_224921): T_Loss: 0.113334 V_Loss: 0.399959 IoU: 0.684 Dice: 0.777 \n",
      "41EP(250411_224958): T_Loss: 0.11365 V_Loss: 0.382396 IoU: 0.686 Dice: 0.779 \n",
      "42EP(250411_225036): T_Loss: 0.112527 V_Loss: 0.370908 IoU: 0.691 Dice: 0.785 \n",
      "43EP(250411_225114): T_Loss: 0.105935 V_Loss: 0.396342 IoU: 0.695 Dice: 0.789 \n",
      "44EP(250411_225152): T_Loss: 0.100109 V_Loss: 0.381378 IoU: 0.691 Dice: 0.784 \n",
      "45EP(250411_225230): T_Loss: 0.097563 V_Loss: 0.38181 IoU: 0.697 Dice: 0.79 \n",
      "Test Start Time: 250411_225230\n",
      "Best Epoch: 20\n",
      "Test(250411_225247): Loss: 0.317944 PA: 0.94 IoU: 0.706 Dice: 0.799 Recall: 0.805 Precision: 0.838 F1 Score: 0.799\n",
      "End 250411_225247\n",
      "DeepLab_V3_Plus_Effi_U_Trans2 (Iter 2)\n",
      "2025-04-11 22:52:48,802 - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b5.sw_in12k_ft_in1k)\n",
      "2025-04-11 22:52:49,069 - [timm/efficientnet_b5.sw_in12k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-04-11 22:52:49,317 - Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Training Start Time: 250411_225249\n",
      "1EP(250411_225409): T_Loss: 1.055371 V_Loss: 0.895133 IoU: 0.529 Dice: 0.641 Best Epoch: 1 Loss: 0.895133\n",
      "2EP(250411_225439): T_Loss: 0.837722 V_Loss: 1.280749 IoU: 0.575 Dice: 0.688 \n",
      "3EP(250411_225513): T_Loss: 0.719875 V_Loss: 0.894935 IoU: 0.604 Dice: 0.714 Best Epoch: 3 Loss: 0.894935\n",
      "4EP(250411_225549): T_Loss: 0.631189 V_Loss: 0.545438 IoU: 0.637 Dice: 0.738 Best Epoch: 4 Loss: 0.545438\n",
      "5EP(250411_225627): T_Loss: 0.558834 V_Loss: 0.527521 IoU: 0.645 Dice: 0.748 Best Epoch: 5 Loss: 0.527521\n",
      "6EP(250411_225705): T_Loss: 0.489296 V_Loss: 0.473388 IoU: 0.649 Dice: 0.751 Best Epoch: 6 Loss: 0.473388\n",
      "7EP(250411_225743): T_Loss: 0.434752 V_Loss: 0.426873 IoU: 0.651 Dice: 0.753 Best Epoch: 7 Loss: 0.426873\n",
      "8EP(250411_225821): T_Loss: 0.374304 V_Loss: 0.403331 IoU: 0.666 Dice: 0.765 Best Epoch: 8 Loss: 0.403331\n",
      "9EP(250411_225900): T_Loss: 0.338552 V_Loss: 0.379002 IoU: 0.666 Dice: 0.764 Best Epoch: 9 Loss: 0.379002\n",
      "10EP(250411_225938): T_Loss: 0.327589 V_Loss: 0.374337 IoU: 0.671 Dice: 0.772 Best Epoch: 10 Loss: 0.374337\n",
      "11EP(250411_230016): T_Loss: 0.282603 V_Loss: 0.353119 IoU: 0.673 Dice: 0.771 Best Epoch: 11 Loss: 0.353119\n",
      "12EP(250411_230054): T_Loss: 0.268499 V_Loss: 0.374581 IoU: 0.662 Dice: 0.763 \n",
      "13EP(250411_230131): T_Loss: 0.251928 V_Loss: 0.372829 IoU: 0.673 Dice: 0.773 \n",
      "14EP(250411_230209): T_Loss: 0.229807 V_Loss: 0.349789 IoU: 0.682 Dice: 0.78 Best Epoch: 14 Loss: 0.349789\n",
      "15EP(250411_230247): T_Loss: 0.21353 V_Loss: 0.346072 IoU: 0.686 Dice: 0.78 Best Epoch: 15 Loss: 0.346072\n",
      "16EP(250411_230325): T_Loss: 0.214705 V_Loss: 0.3584 IoU: 0.678 Dice: 0.777 \n",
      "17EP(250411_230403): T_Loss: 0.208744 V_Loss: 0.341458 IoU: 0.696 Dice: 0.794 Best Epoch: 17 Loss: 0.341458\n",
      "18EP(250411_230441): T_Loss: 0.203075 V_Loss: 0.363751 IoU: 0.677 Dice: 0.774 \n",
      "19EP(250411_230519): T_Loss: 0.192587 V_Loss: 0.343195 IoU: 0.689 Dice: 0.784 \n",
      "20EP(250411_230557): T_Loss: 0.18622 V_Loss: 0.346167 IoU: 0.69 Dice: 0.788 \n",
      "21EP(250411_230635): T_Loss: 0.194515 V_Loss: 0.36419 IoU: 0.681 Dice: 0.78 \n",
      "22EP(250411_230713): T_Loss: 0.16852 V_Loss: 0.342488 IoU: 0.707 Dice: 0.801 \n",
      "23EP(250411_230750): T_Loss: 0.170289 V_Loss: 0.337568 IoU: 0.688 Dice: 0.785 Best Epoch: 23 Loss: 0.337568\n",
      "24EP(250411_230825): T_Loss: 0.15639 V_Loss: 0.337455 IoU: 0.696 Dice: 0.791 Best Epoch: 24 Loss: 0.337455\n",
      "25EP(250411_230902): T_Loss: 0.151436 V_Loss: 0.351769 IoU: 0.697 Dice: 0.793 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 실험 수행\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mDo_Experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[3], line 402\u001b[0m, in \u001b[0;36mDo_Experiment\u001b[0;34m(iteration, model_name, model, train_loader, validation_loader, test_loader, Optimizer, lr, number_of_classes, epochs, Metrics, df, device, transform)\u001b[0m\n\u001b[1;32m    400\u001b[0m train_start_time \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 402\u001b[0m     Train_Loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    406\u001b[0m     outputs, targets  \\\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;241m=\u001b[39m validate(validation_loader, \n\u001b[1;32m    408\u001b[0m       model, criterion, device\n\u001b[1;32m    409\u001b[0m       )\n",
      "Cell \u001b[0;32mIn[3], line 240\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, epoch, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m    238\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output,target)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    239\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 240\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    242\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/carseg/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/carseg/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "Experiments_Time=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "print('Experiment Start Time:',Experiments_Time)\n",
    "Metrics=['Experiment Time','Train Time', 'Iteration','Model Name', 'Val_Loss', 'Test_Loss','PA', 'IoU', 'Dice', 'Recall', 'Precision', 'F1 Score', 'Total Params','Train-Predction Time','Best Epoch','Time per Epoch', 'Loss Function', 'LR', 'Batch size', '#Epochs', 'DIR']\n",
    "df = pd.DataFrame(index=None, columns=Metrics)\n",
    "output_root = f'output_proposedd/DeepLab_V3_Plus_Effi_U_Trans2(256)/output_{Experiments_Time}'\n",
    "os.makedirs(output_root, exist_ok = True)\n",
    "\n",
    "# iterations = [7, 8, 9, 10]\n",
    "\n",
    "# for iteration in iterations:\n",
    "# COCO 데이터셋 기반 반복 실험 코드\n",
    "for iteration in range(iterations[0], iterations[1] + 1):\n",
    "    seed = iteration\n",
    "    control_random_seed(seed)\n",
    "    \n",
    "    # 각 iteration에 맞는 split 폴더 설정\n",
    "    Dataset_dir = f'CarDD_release/splits/split{str(iteration).zfill(2)}'\n",
    "    \n",
    "    # COCO 데이터 로드\n",
    "    coco_data = load_coco_data(Dataset_dir)\n",
    "    \n",
    "    # 데이터 로더 생성\n",
    "    train_loader = create_dataloader(\n",
    "        coco_data, \"training\", os.path.join(Dataset_dir, \"training\"), batch_size, aug=True\n",
    "    )\n",
    "    validation_loader = create_dataloader(\n",
    "        coco_data, \"validation\", os.path.join(Dataset_dir, \"validation\"), batch_size, aug=False\n",
    "    )\n",
    "    test_loader = create_dataloader(\n",
    "        coco_data, \"test\", os.path.join(Dataset_dir, \"test\"), batch_size, aug=False\n",
    "    )\n",
    "\n",
    "    # 반복 실험 실행\n",
    "    for model_name in model_names:\n",
    "        print(f'{model_name} (Iter {iteration})')\n",
    "        output_dir = output_root + f'/{model_name}_Iter_{iteration}'\n",
    "        copy_sourcefile(output_dir, src_dir='src')\n",
    "        control_random_seed(seed)\n",
    "\n",
    "        # 모델 초기화\n",
    "        model = str_to_class(model_name)(in_channels, number_of_classes)\n",
    "        device_ids = [2]\n",
    "        device = torch.device(\"cuda:\" + str(device_ids[0]))\n",
    "        if len(device_ids) > 1:\n",
    "            model = torch.nn.DataParallel(model, device_ids=device_ids).to(device)\n",
    "        else:\n",
    "            model = model.to(device)\n",
    "\n",
    "        # 실험 수행\n",
    "        df = Do_Experiment(\n",
    "            seed, model_name, model, train_loader, validation_loader, test_loader,\n",
    "            optimizer, lr, number_of_classes, epochs, Metrics, df, device, None\n",
    "        )\n",
    "\n",
    "        # 결과 저장\n",
    "        try:\n",
    "            df.to_csv(output_root + '/' + f'output_CarDD_DeepLab_V3_Plus_Effi_U_Trans2(256)_{Experiments_Time}.csv', index=False, header=True, encoding=\"cp949\")\n",
    "        except:\n",
    "            now = datetime.now()\n",
    "            tmp_date = now.strftime(\"%y%m%d_%H%M%S\")\n",
    "            df.to_csv(output_root + '/' + f'output_CarDD_DeepLab_V3_Plus_Effi_U_Trans2(256)_{Experiments_Time}_{tmp_date}_tmp.csv', index=False, header=True, encoding=\"cp949\")\n",
    "\n",
    "print('End')\n",
    "os._exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
